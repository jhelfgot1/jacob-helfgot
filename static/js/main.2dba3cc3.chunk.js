(this["webpackJsonpjacob-helfgot"]=this["webpackJsonpjacob-helfgot"]||[]).push([[0],{103:function(t,n,e){},104:function(t,n,e){},110:function(t,n,e){},111:function(t,n,e){},359:function(t,n,e){},360:function(t,n,e){},364:function(t,n,e){"use strict";e.r(n);var i=e(0),o=e.n(i),r=e(20),a=e.n(r),s=(e(103),e(104),e(18)),l=e(9),c=e(31),d=e(54),u=e(72),p=e(1),h=function(t){var n=t.headerContent,e=t.pageContent;return Object(p.jsxs)("div",{style:{margin:"60px"},className:"overflow-auto ",children:[Object(p.jsx)("h1",{children:n}),Object(p.jsx)("div",{className:"mt-2 mr-5",children:e.map((function(t){return Object(p.jsx)("div",{children:t})}))})]})},f=function(){var t=[Object(p.jsxs)("p",{children:["I'm a full-stack software engineer. Head on over to the"," ",Object(p.jsx)(s.b,{to:"/about",children:'"About Me"'})," page if you want a little more info on who I am and what I'm all about."]}),Object(p.jsx)("p",{children:"I do appreciate you stopping by. I just recently started putting this site together, so forgive how barren it is for the time-being. My plan is to use this site as a sandbox to explore new design techniques, so checkback periodically to see how things are progressing!"}),Object(p.jsx)("p",{children:"In the coming weeks I'll be putting some of my past projects on display, further building out the site, and making the whole thing a bit more snazzy."})];return Object(p.jsx)(o.a.Fragment,{children:Object(p.jsx)(h,{headerContent:"Hi! I'm Jacob",pageContent:t})})},g=e(93),m=e(98),b=e(73),x=function(){var t=Object(p.jsx)(b.a,{id:"popover-basic",children:Object(p.jsx)(b.a.Content,{children:"If you want to hear more about my work in these roles, reach out! To avoid potential security and compliance ramifications, both organizations strongly cautioned against being too vocal about our work in public forums."})}),n=[Object(p.jsxs)("p",{children:["Like I said, I'm a software engineer. I've worked at JP Morgan and American Express writing back-end applications with C++, Java, and Node, and have written front-end apps with React. I love coding, diving into interesting problems, automating the annoying stuff, learning new things, and working with others to take on big challenges."," ",Object(p.jsx)(m.a,{placement:"bottom",overlay:t,children:Object(p.jsx)(g.a,{pill:!0,variant:"light",children:"i"})})]}),Object(p.jsx)("p",{children:"Solving tough problems gets me out of bed in the morning, and I couldn't imagine doing anything else. But it took me awhile to figure that out. I tried out a bunch of things in college, from environmental science to econcomics. Then I was pretty sure I had it sorted when I switched to philosophy."}),Object(p.jsx)("p",{children:'Then, one day I had a meeting with my advisor and she made an off-hand recommendation that I give comp sci a try. I thought, "Sure, why not?"'}),Object(p.jsxs)("p",{children:["And the rest was history. Well, almost. I spent the first month of my intro CS course banging my head against a wall. Things just were not clicking, and I was ",Object(p.jsx)("strong",{children:"not"})," okay with that."]}),Object(p.jsx)("p",{children:"Then loops started making a bit of sense, then objects, then recursion (kind of, that one may have admittedly taken a bit longer). And then I was getting through my assignments with what now feels like an acceptable amount of head-against-the-wall banging."}),Object(p.jsxs)("p",{children:["Now I'm looking for my next opportunity at an exciting, dynamic company where I can get my hands-dirty wearing as many hats as possible. If you're looking for a talented and passionate engineer, or know someone who is, give me a shout through any of the channels listed"," ",Object(p.jsx)(s.b,{to:"/contact",children:"here"}),"."]})];return Object(p.jsx)(h,{headerContent:"Who is this Jacob guy?",pageContent:n})},_=function(){var t=[Object(p.jsx)("p",{children:"Reach out to me through any of the following channels:"}),Object(p.jsxs)("ul",{children:[Object(p.jsx)("li",{children:Object(p.jsx)("a",{href:"mailto:jhelfgot1@gmail.com",target:"_blank",children:"Email Me"})}),Object(p.jsx)("li",{children:Object(p.jsx)("a",{href:"https://www.linkedin.com/in/jacob-helfgot-b2b018127/",children:"LinkedIn"})})]}),Object(p.jsxs)("p",{children:["Also, take a look at my"," ",Object(p.jsx)("a",{href:"https://github.com/jhelfgot1",children:"github page"})," if you'd like."]})];return Object(p.jsx)(h,{headerContent:"Get in touch!",pageContent:t})},j=(e(110),e(71)),y=e(53),v=e(55),V=e(46),w=e(74),O=(e(111),e(372)),T=function(t){var n=t.codeSnippet;return Object(p.jsx)("div",{className:"codeblock",children:Object(p.jsx)(O.a,{customStyle:{fontSize:".6em"},showLineNumbers:!0,language:"cpp",children:n})})},M=(e(359),function(t){var n=t.projectName,e=t.projectDescription,i=t.images,o=t.codeSnippets,r=[];if(i)for(var a=0;a<i.length;a+=2)a+1<i.length?r.push(Object(p.jsxs)(j.a,{children:[Object(p.jsx)(y.a,{md:6,children:i[a]}),Object(p.jsx)(y.a,{md:6,children:i[a+1]})]})):r.push(Object(p.jsx)(j.a,{children:Object(p.jsx)(y.a,{md:6,children:i[a]})}));return Object(p.jsxs)("div",{className:"mt-3 p-2 border rounded border",children:[Object(p.jsx)("h2",{children:n}),e,r,o?Object(p.jsxs)("div",{children:[Object(p.jsx)("h3",{className:"mt-3",children:"Code Snippets"}),Object(p.jsx)(v.a,{defaultActiveKey:"0",children:o.map((function(t){var n=t.codeSnippet,e=t.name;return Object(p.jsxs)(w.a,{children:[Object(p.jsx)(w.a.Header,{children:Object(p.jsx)(v.a.Toggle,{as:V.a,variant:"link",eventKey:e,children:e})}),Object(p.jsx)(v.a.Collapse,{eventKey:e,children:Object(p.jsx)(T,{name:e,codeSnippet:n})})]})}))})]}):null]})}),P=(e(360),function(t){var n=t.imageSrc,e=t.caption;return Object(p.jsxs)("div",{className:"imageWithCaption",children:[Object(p.jsx)("img",{src:n,fluid:!0,responsive:!0}),e?Object(p.jsx)("p",{children:e}):null]})}),L=function(){var t=Object(p.jsxs)("p",{children:["Here are some images I produced as part of a project to write a"," ",Object(p.jsx)("a",{href:"https://en.wikipedia.org/wiki/Ray_tracing_(graphics)",children:"ray-tracing"})," ","image renderer."]}),n=Object(p.jsxs)("div",{children:[Object(p.jsxs)("p",{children:["This assignment was to implement"," ",Object(p.jsx)("a",{href:"https://en.wikipedia.org/wiki/Texture_mapping",children:"basic texturing techniques"})," ","used in 3D rasterization pipelines."]}),Object(p.jsx)("p",{children:"Texture mapping allows detailed image textures to be mapped onto simpler objects, lending them a more realistic appearance."}),Object(p.jsx)("p",{children:"See below the 2D textures that are then mapped onto the corresponding 3D objects."})]}),e=Object(p.jsxs)("div",{children:[Object(p.jsx)("p",{children:"This was our first project and served as a primer on C++ and an intro to coding in reference to geometric spaces."}),Object(p.jsx)("p",{children:"The assignment was to write two programs that both performed operations on a collection of points in 2D-space."}),Object(p.jsxs)("p",{children:["The first program took as input a list representation of points in 2D space and generated the convex-hull (the smallest bounding polygon) of the points. This was executed using the"," ",Object(p.jsx)("a",{href:"https://en.wikipedia.org/wiki/Graham_scan",children:"Graham Scan"})," ","algorithm."]}),Object(p.jsxs)("p",{children:["The second program took a list of points as input, as well as a polygon represented as a list of vectors. The program then computed which of the points fell within the given polygon using the"," ",Object(p.jsx)("a",{href:"https://en.wikipedia.org/wiki/Point_in_polygon",children:"Point in Polygon"})," ","test."]})]});return Object(p.jsxs)("div",{style:{margin:"60px"},className:"overflow-auto ",children:[Object(p.jsx)("h1",{children:"Computer Graphics"}),Object(p.jsx)("p",{children:"On this page you can find some of the images produced from a few of the graphics projects I completed during my CG course at NYU, along with some of the associated code."}),Object(p.jsx)(M,{projectName:"Ray Tracing",projectDescription:t,images:[Object(p.jsx)(P,{imageSrc:"/jacob-helfgot/images/finalRender.png"}),Object(p.jsx)(P,{imageSrc:"/jacob-helfgot/images/depthOfField.png"})],codeSnippets:[{name:"Ray Tracer",codeSnippet:'////////////////////////////////////////////////////////////////////////////////\n// C++ include\n#include <fstream>\n#include <iostream>\n#include <limits>\n#include <memory>\n#include <string>\n#include <vector>\n\n// Eigen for matrix operations\n#include <Eigen/Dense>\n\n// Image writing library\n#define STB_IMAGE_WRITE_IMPLEMENTATION // Do not include this line twice in your project!\n#include "stb_image_write.h"\n#include "utils.h"\n\n// JSON parser library (https://github.com/nlohmann/json)\n#include "json.hpp"\nusing json = nlohmann::json;\n\n// Shortcut to avoid Eigen:: everywhere, DO NOT USE IN .h\nusing namespace Eigen;\n\nint numberArgs;\nint totalIntersections = 0;\nstd::vector<std::string> arguments;\n\n\n////////////////////////////////////////////////////////////////////////////////\n// Define types & classes\n////////////////////////////////////////////////////////////////////////////////\n\nstruct Ray {\n\tVector3d origin;\n\tVector3d direction;\n\tRay() { }\n\tRay(Vector3d o, Vector3d d) : origin(o), direction(d) { }\n};\n\nstruct Light {\n\tVector3d position;\n\tVector3d intensity;\n};\n\nstruct Intersection {\n\tVector3d position;\n\tVector3d normal;\n\tdouble ray_param;\n    double tVal;\n};\n\nstruct Camera {\n\tbool is_perspective;\n\tVector3d position;\n\tdouble field_of_view; // between 0 and PI\n\tdouble focal_length;\n\tdouble lens_radius; // for depth of field\n};\n\nstruct Material {\n\tVector3d ambient_color;\n\tVector3d diffuse_color;\n\tVector3d specular_color;\n\tdouble specular_exponent; // Also called "shininess"\n\n\tVector3d reflection_color;\n\tVector3d refraction_color;\n\tdouble refraction_index;\n};\n\nstruct Object {\n\tMaterial material;\n    std::string type;\n\tvirtual ~Object() = default; // Classes with virtual methods should have a virtual destructor!\n\tvirtual bool intersect(const Ray &ray, Intersection &hit) = 0;\n};\n\n// We use smart pointers to hold objects as this is a virtual class\ntypedef std::shared_ptr<Object> ObjectPtr;\n\nstruct Sphere : public Object {\n\tVector3d position;\n\tdouble radius;\n\tvirtual ~Sphere() = default;\n\tvirtual bool intersect(const Ray &ray, Intersection &hit) override;\n};\n\nstruct Parallelogram : public Object {\n\tVector3d origin;\n\tVector3d u;\n\tVector3d v;\n    std::string type = "pGram";\n\tvirtual ~Parallelogram() = default;\n\tvirtual bool intersect(const Ray &ray, Intersection &hit) override;\n};\n\nstruct Scene {\n\tVector3d background_color;\n\tVector3d ambient_light;\n\n\tCamera camera;\n    std::vector<Sphere*> spheres;\n\tstd::vector<Material> materials;\n\tstd::vector<Light> lights;\n\tstd::vector<ObjectPtr> objects;\n};\n\n////////////////////////////////////////////////////////////////////////////////\n\nbool Sphere::intersect(const Ray &ray, Intersection &hit) {\n\t// TODO:\n\t//\n\t// Compute the intersection between the ray and the sphere\n\t// If the ray hits the sphere, set the result of the intersection in the\n\t// struct \'hit\'\n\n\treturn false;\n}\n\nbool Parallelogram::intersect(const Ray &ray, Intersection &hit) {\n\t// TODO\n\treturn false;\n}\n\nbool affectedByLight(const Intersection &intersection, const Light &light) {\n\n    return false;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n// Define ray-tracing functions\n////////////////////////////////////////////////////////////////////////////////\n\n// Function declaration here (could be put in a header file)\nVector3d ray_color(const Scene &scene, const Ray &ray, const Object &object, const Intersection &hit, int max_bounce);\nObject * find_nearest_object(const Scene &scene, const Ray &ray, Intersection &hit, double &closest_t);\nbool is_light_visible(const Scene &scene, const Ray &ray, const Light &light);\nVector3d shoot_ray(const Scene &scene, const Ray &ray, int max_bounce);\n\nVector3d getProjectionOfCenterOntoRay(const Ray &ray, const Sphere &sphere) {\n\n    Vector3d a = Vector3d(sphere.position[0], sphere.position[1], sphere.position[2]);\n    Vector3d b = ray.origin + Vector3d(ray.direction[0], ray.direction[1], ray.direction[2]);\n\n\n    return ((a.dot(b))/ pow(b.norm(), 2)) * b;\n}\n// -----------------------------------------------------------------------------\n\nIntersection raySphereIntersection(const Sphere &sphereObj, const Ray &ray) {\n    Intersection returnIntersection;\n    Vector3d normalizedDirection;\n    normalizedDirection = ray.direction.normalized();\n    double originHitConstant;\n    double distanceMultPlus;\n    double distanceMultMinus;\n    double rootVal = std::pow(normalizedDirection.dot(ray.origin-sphereObj.position), 2);\n    rootVal = rootVal - std::pow((ray.origin - sphereObj.position).norm(), 2) + std::pow(sphereObj.radius, 2);\n    if (rootVal < 0) {\n        returnIntersection.tVal = -1;\n        return returnIntersection;\n    }\n    else {\n        originHitConstant = -1 * (normalizedDirection.dot(ray.origin - sphereObj.position));\n        distanceMultMinus = originHitConstant - std::sqrt(rootVal);\n        distanceMultPlus = originHitConstant + std::sqrt(rootVal);\n        if (distanceMultMinus > 0) {\n            returnIntersection.position = ray.origin + normalizedDirection * distanceMultMinus;\n            returnIntersection.normal = returnIntersection.position - sphereObj.position;\n            returnIntersection.tVal = distanceMultMinus;\n\n        }\n        else {\n            returnIntersection.position = ray.origin + normalizedDirection * distanceMultPlus;\n            returnIntersection.normal = returnIntersection.position - sphereObj.position;\n            returnIntersection.tVal = distanceMultPlus;\n        }\n        if (returnIntersection.tVal < .01) {\n            returnIntersection.tVal = -1;\n        }\n        return returnIntersection;\n\n\n    }\n}\n/*\nIntersection getSphereIntersection(const Sphere &sphereObj, const Ray &ray) {\n    Intersection returnIntersection;\n    double distanceFromIntersection;\n    Sphere sphere;\n    sphere.position = sphereObj.position;\n    sphere.radius = sphereObj.radius;\n    Vector3d originToSphereCenter = sphere.position - ray.origin;\n    //Center of sphere is behind the origin of the vector.\n    if (ray.direction.dot(originToSphereCenter) < 0.0) {\n        if (originToSphereCenter.norm() > sphere.radius) {\n            returnIntersection.tVal = -1;\n            return returnIntersection;\n        }\n        //The origin of the ray is on the surface of the sphere.\n        else if(originToSphereCenter.norm() == sphere.radius) {\n            returnIntersection.position = ray.origin;\n            returnIntersection.tVal = 0.0;\n            returnIntersection.normal = originToSphereCenter * -1;\n            return returnIntersection;\n        }\n        //The origin is inside the sphere.\n        else {\n            Vector3d projectionFromCenter = getProjectionOfCenterOntoRay(ray, sphere);\n            double projectionDistance = sqrt(pow(sphere.radius, 2) -  pow((projectionFromCenter - sphere.position).norm(), 2));\n            double distanceFromIntersection = projectionDistance - (projectionFromCenter - ray.origin).norm();\n            returnIntersection.position = ray.origin + ray.direction * distanceFromIntersection;\n            returnIntersection.tVal = distanceFromIntersection;\n            returnIntersection.normal = -1*(sphere.position - returnIntersection.position);\n            return returnIntersection;\n        }\n    }\n    else {\n        Vector3d projectionOntoRay = getProjectionOfCenterOntoRay(ray, sphere);\n        //If there is no intersection...\n        if ((sphere.position - projectionOntoRay).norm() > sphere.radius) {\n            returnIntersection.tVal = -1;\n            return returnIntersection;\n        }\n        //Does intersect sphere.\n        else {\n            double projectionDistance = sqrt(pow(sphere.radius, 2) -  pow((projectionOntoRay - sphere.position).norm(), 2));\n            //Origin is outside of the sphere..\n            if (originToSphereCenter.norm() > sphere.radius) {\n                distanceFromIntersection = (projectionOntoRay - ray.origin).norm() - projectionDistance;\n            }\n            //origin is inside sphere...\n            else {\n                distanceFromIntersection = (projectionOntoRay - ray.origin).norm() + projectionDistance;\n            }\n            returnIntersection.position = ray.origin + ray.direction * distanceFromIntersection;\n            returnIntersection.tVal = distanceFromIntersection;\n            returnIntersection.normal = -1*(sphere.position);\n            return returnIntersection;\n        }\n    }\n}\n*/\n\nVector3d ray_color(const Scene &scene, const Ray &ray, const Object &obj, const Intersection &hit, int max_bounce) {\n\t// Material for hit object\n\n\tconst Material &mat = obj.material;\n\n\t// Ambient light contribution\n\tVector3d ambient_color = obj.material.ambient_color.array() * scene.ambient_light.array();\n\n\t// Punctual lights contribution (direct lighting)\n\tVector3d lights_color(0, 0, 0);\n\tfor (const Light &light : scene.lights) {\n\t\tVector3d Li = (light.position - hit.position).normalized();\n\n        Ray rayToLight;\n        rayToLight.origin = hit.position;\n        rayToLight.direction = light.position - hit.position;\n\t\tVector3d N = hit.normal;\n        bool affectedByCurrentLight;\n        affectedByCurrentLight = true;\n\t\t// TODO: Shoot a shadow ray to determine if the light should affect the intersection point\n        for (int i = 0; i < scene.spheres.size(); i++) {\n            Intersection potentialIntersect = raySphereIntersection(*scene.spheres[i], rayToLight);\n            if (potentialIntersect.tVal != -1) {\n                affectedByCurrentLight = false;\n                break;\n            }\n        }\n\n        if (affectedByCurrentLight) {\n\n            Vector3d diffuse = mat.diffuse_color * std::max(Li.dot(N), 0.0);\n\n            // TODO: Specular contribution\n\n            Vector3d h = ((-1*ray.direction) + rayToLight.direction)/((-1*ray.direction) + rayToLight.direction).norm();\n            Vector3d specular = mat.specular_color * std::pow(std::max(h.dot(N), 0.0), mat.specular_exponent);\n\n            // Attenuate lights according to the squared distance to the lights\n            Vector3d D = light.position - hit.position;\n            lights_color += (diffuse + specular).cwiseProduct(light.intensity) /  D.squaredNorm();\n        }\n\t\t// Diffuse contribution\n\n\t}\n\n\t// TODO: Compute the color of the reflected ray and add its contribution to the current point color.\n\n\n    Vector3d reflection_color(0,0,0);\n\n    if (max_bounce > 0) {\n        Vector3d r = ray.direction - (2 * ray.direction.dot(hit.normal) * hit.normal);\n        Ray newRay;\n        newRay.direction = r;\n        newRay.origin = hit.position + hit.normal * .001;\n        reflection_color = .4 * shoot_ray(scene, newRay, max_bounce - 1);\n    }\n\n\n\n\n\t// TODO: Compute the color of the refracted ray and add its contribution to the current point color.\n\t//       Make sure to check for total internal reflection before shooting a new ray.\n\tVector3d refraction_color(0, 0, 0);\n\n\tif (max_bounce > 0) {\n\t\tdouble r = mat.refraction_index;\n\t\tVector3d rayNorm = ray.direction.normalized();\n\t\tdouble c = (-1*hit.normal.normalized()).dot(rayNorm);\n\t\tRay refractedRay;\n\t\trefractedRay.origin = hit.position - hit.normal * .001;\n\t\trefractedRay.direction = r*rayNorm + ((r*c - std::sqrt(1-(std::pow(r, 2) * (1 - std::pow(c,2))))) * hit.normal.normalized());\n\t\trefraction_color = .2 * shoot_ray(scene, refractedRay, max_bounce - 1);\n\t}\n\t// Rendering equation\n\tVector3d C = ambient_color + lights_color + reflection_color + refraction_color;\n\n\treturn C;\n}\n\n\n\n// -----------------------------------------------------------------------------\n\n\n\n\nObject * find_nearest_object(const Scene &scene, const Ray &ray, Intersection &closest_hit) {\n\n    // Find the object in the scene that intersects the ray first\n    // The function must return \'nullptr\' if no object is hit, otherwise it must\n    // return a pointer to the hit object, and set both arguments \'hit\' and\n    // \'closest_t\' to their expected values\n\n    int closest_index = -1;\n    double minTVal = 0;\n    Intersection closestIntersection;\n    for (int i = 0; i < scene.spheres.size(); i++) {\n        Intersection thisIntersection = raySphereIntersection(*scene.spheres[i], ray);\n\n        if (thisIntersection.tVal > 0) {\n\n            if (minTVal == 0 || thisIntersection.tVal < minTVal) {\n                minTVal = thisIntersection.tVal;\n                closest_index = i;\n                closestIntersection = thisIntersection;\n            }\n        }\n\n    }\n\n\n\tif (closest_index < 0) {\n\t\t// Return a NULL pointer\n\t\treturn nullptr;\n\t} else {\n        totalIntersections++;\n\t\t// Return a pointer to the hit object. Don\'t forget to set \'closest_hit\' accordingly!\n        closest_hit = closestIntersection;\n\t\treturn scene.objects[closest_index].get();\n\t}\n}\n\nbool is_light_visible(const Scene &scene, const Ray &ray, const Light &light) {\n    return true;\n}\n\nVector3d shoot_ray(const Scene &scene, const Ray &ray, int max_bounce) {\n\tIntersection hit;\n\tif (Object * obj = find_nearest_object(scene, ray, hit)) {\n\t\t// \'obj\' is not null and points to the object of the scene hit by the ray\n\t\treturn ray_color(scene, ray, *obj, hit, max_bounce);\n\t} else {\n\t\t// \'obj\' is null, we must return the background color\n\t\treturn scene.background_color;\n\t}\n}\n\n////////////////////////////////////////////////////////////////////////////////\n\nvoid render_scene(const Scene &scene) {\n\tstd::cout << "Simple ray tracer." << std::endl;\n\n\n\tint w = 640;\n\tint h = 480;\n\tMatrixXd R = MatrixXd::Zero(w, h);\n\tMatrixXd G = MatrixXd::Zero(w, h);\n\tMatrixXd B = MatrixXd::Zero(w, h);\n\tMatrixXd A = MatrixXd::Zero(w, h); // Store the alpha mask\n\n\t// The camera always points in the direction -z\n\t// The sensor grid is at a distance \'focal_length\' from the camera center,\n\t// and covers an viewing angle given by \'field_of_view\'.\n\tdouble aspect_ratio = double(w) / double(h);\n\n\tdouble hVal = (tan(scene.camera.field_of_view / 2) * scene.camera.focal_length);\n\tstd::cout << "Hval: " << hVal << std::endl;\n\tdouble scale_y = hVal; // TODO: Stretch the pixel grid by the proper amount here\n\tdouble scale_x = hVal * aspect_ratio; //\n\tVector3d lensePosition = scene.camera.position;\n\n\t// The pixel grid through which we shoot rays is at a distance \'focal_length\'\n\t// from the sensor, and is scaled from the canonical [-1,1] in order\n\t// to produce the target field of view.\n\tVector3d grid_origin(-scale_x, scale_y, 0);\n\tVector3d x_displacement(2.0 / w * scale_x, 0, 0);\n\tVector3d y_displacement(0, -2.0 / h * scale_y, 0);\n\tdouble focal_length = scene.camera.focal_length;\n\tint samples = 3;\n\n\n\tfor (unsigned i = 0; i < w; ++i) {\n\t\tfor (unsigned j = 0; j < h; ++j) {\n\t\t\t// TODO: Implement depth of field\n\n\n\n\t\t\t\tVector3d shift = grid_origin + (i + 0.5) * x_displacement + (j + 0.5) * y_displacement;\n\n\t\t\t\t// Prepare the ray\n\t\t\t\tRay ray;\n\n\t\t\t\tif (scene.camera.is_perspective) {\n\t\t\t\t\tray.origin = lensePosition;\n\t\t\t\t\tray.direction = shift - lensePosition;\n\n\t\t\t\t\t// TODO\n\t\t\t\t} else {\n\t\t\t\t\t// Orthographic camera\n\t\t\t\t\tray.origin = scene.camera.position + Vector3d(shift[0], shift[1], 0);\n\t\t\t\t\tray.direction = Vector3d(0, 0, -1);\n\t\t\t\t}\n\n\n\n\t\t\t\tint max_bounce = 5;\n\t\t\t\tVector3d C = shoot_ray(scene, ray, max_bounce);\n\t\t\t\tif (scene.camera.is_perspective) {\n\t\t\t\t\t//Extra samples for depth of field\n\t\t\t\t\tfor (int i = 1; i < samples; i++) {\n\t\t\t\t\t\tint randMaxBounce = 5;\n\t\t\t\t\t\tdouble randX = ((double)(rand() % 8))/100;\n\t\t\t\t\t\tdouble randY = ((double)(rand() % 8))/100;\n\t\t\t\t\t\tRay randomRay;\n\t\t\t\t\t\trandomRay.origin = lensePosition + Vector3d(randX, randY, 0);\n\t\t\t\t\t\trandomRay.direction = shift - randomRay.origin;\n\t\t\t\t\t\tC = C + shoot_ray(scene, randomRay, randMaxBounce);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tC = C/samples;\n\t\t\t\tR(i, j) = C(0);\n\t\t\t\tG(i, j) = C(1);\n\t\t\t\tB(i, j) = C(2);\n\t\t\t\tA(i, j) = 1;\n\t//            R(i, j) = 10;\n\t//\t\t\tG(i, j) = 0;\n\t//\t\t\tB(i, j) = 0;\n\t//\t\t\tA(i, j) = 1;\n\n\t\t}\n\t}\n\n\t// Save to png\n    if (numberArgs < 3) {\n        const std::string filename("../img/raytrace.png");\n        write_matrix_to_png(R, G, B, A, filename);\n\n    }\n    else {\n        const std::string filename("../img/" + arguments[2]);\n        write_matrix_to_png(R, G, B, A, filename);\n    }\n\n\n}\n\n////////////////////////////////////////////////////////////////////////////////\n\nScene load_scene(const std::string &filename) {\n\tScene scene;\n\n\t// Load json data from scene file\n\tjson data;\n\n\tstd::ifstream in(filename);\n\tin >> data;\n\n\t// Helper function to read a Vector3d from a json array\n\tauto read_vec3 = [] (const json &x) {\n\t\treturn Vector3d(x[0], x[1], x[2]);\n\t};\n\n\t// Read scene info\n\tscene.background_color = read_vec3(data["Scene"]["Background"]);\n\tscene.ambient_light = read_vec3(data["Scene"]["Ambient"]);\n\n\t// Read camera info\n\tscene.camera.is_perspective = data["Camera"]["IsPerspective"];\n\tscene.camera.position = read_vec3(data["Camera"]["Position"]);\n\tscene.camera.field_of_view = data["Camera"]["FieldOfView"];\n\tscene.camera.focal_length = data["Camera"]["FocalLength"];\n\tscene.camera.lens_radius = data["Camera"]["LensRadius"];\n\n\t// Read materials\n\tfor (const auto &entry : data["Materials"]) {\n\t\tMaterial mat;\n\t\tmat.ambient_color = read_vec3(entry["Ambient"]);\n\t\tmat.diffuse_color = read_vec3(entry["Diffuse"]);\n\t\tmat.specular_color = read_vec3(entry["Specular"]);\n\t\tmat.reflection_color = read_vec3(entry["Mirror"]);\n\t\tmat.refraction_color = read_vec3(entry["Refraction"]);\n\t\tmat.refraction_index = entry["RefractionIndex"];\n\t\tmat.specular_exponent = entry["Shininess"];\n\t\tscene.materials.push_back(mat);\n\t}\n\n\t// Read lights\n\tfor (const auto &entry : data["Lights"]) {\n\t\tLight light;\n\t\tlight.position = read_vec3(entry["Position"]);\n\t\tlight.intensity = read_vec3(entry["Color"]);\n\t\tscene.lights.push_back(light);\n\t}\n\n\t// Read objects\n\tfor (const auto &entry : data["Objects"]) {\n\t\tObjectPtr object;\n        Sphere* sp = new Sphere();\n\t\tif (entry["Type"] == "Sphere") {\n\n\t\t\tauto sphere = std::make_shared<Sphere>();\n\t\t\tsphere->position = read_vec3(entry["Position"]);\n\t\t\tsphere->radius = entry["Radius"];\n            sphere->type = "sphere";\n\t\t\tobject = sphere;\n\n            sp->position = read_vec3(entry["Position"]);\n            sp->radius = entry["Radius"];\n\n\t\t} else if (entry["Type"] == "Parallelogram") {\n\t\t\t// TODO\n\t\t}\n\t\tobject->material = scene.materials[entry["Material"]];\n\t\tscene.objects.push_back(object);\n        scene.spheres.push_back(sp);\n\t}\n\n\n\treturn scene;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n\nint main(int argc, char *argv[]) {\n    numberArgs = argc;\n    for (int i = 0; i < argc; i++) {\n        arguments.push_back(argv[i]);\n    }\n\n\tif (argc < 2) {\n\t\tstd::cerr << "Usage: " << argv[0] << " scene.json" << std::endl;\n\t\treturn 1;\n\t}\n\n\tScene scene = load_scene(argv[1]);\n\trender_scene(scene);\n    std::cout<<totalIntersections<<std::endl;\n    for (int i = 0 ; i < scene.spheres.size(); i++) {\n        delete(scene.spheres[i]);\n    }\n\treturn 0;\n}'}]}),Object(p.jsx)(M,{projectName:"Texture Mapping",projectDescription:n,images:[Object(p.jsx)(P,{imageSrc:"/jacob-helfgot/images/bananaUVCoords.png",caption:"A banana texture map overlaid with the correpsonding UV coordinates."}),Object(p.jsx)(P,{imageSrc:"/jacob-helfgot/images/banana.png",caption:"The object with this texture applied"}),Object(p.jsx)(P,{imageSrc:"/jacob-helfgot/images/OrangeUVCoords.png",caption:"The rendered orange."}),Object(p.jsx)(P,{imageSrc:"/jacob-helfgot/images/orange.png",caption:"The rendered orange."})],codeSnippets:[{name:"Main File",codeSnippet:'struct Mesh {\n\tEigen::MatrixXf V; // vertices positions [3 x n]\n    Eigen::MatrixXf originalV; // vertices positions [3 x n]\n    Eigen::MatrixXf originalVN; // vertices positions [3 x n]\n\tEigen::MatrixXf VT; // texture coordinates [2 x n]\n\tEigen::MatrixXf VN; // vertices normals [3 x n]\n\tEigen::MatrixXi F; // triangles indices [3 x m]\n\n\tEigen::MatrixXf textureCoords; //uv texture coordinates [2 X m]\n\tEigen::Matrix4f initialTransformation = Eigen::Matrix4f::Identity();\n\tEigen::Matrix4f initialTransformationNormals = Eigen::Matrix4f::Identity();\n\n\t// VBO storing vertex position attributes\n\tVertexBufferObject V_vbo;\n\tVertexBufferObject tex_vbo;\n    VertexBufferObject norm_vbo;\n\n\n\t// VBO storing vertex indices (element buffer)\n\tVertexBufferObject F_vbo;\n\n\t// VAO storing the layout of the shader program for the object \'fruit\'\n\tVertexArrayObject vao;\n\n\t// Texture data\n\tImage pixels_color; // 2D array of pixel data\n    Image normal_texture;\n    GLuint textures[2];\n};\n\nMesh fruit;\nint currentModel;\nbool showingUVMapping;\nbool usingMultipleTextures;\nbool useBumpMapping;\n////////////////////////////////////////////////////////////////////////////////\n\nvoid compute_tangent_frame(\n\tconst Eigen::MatrixXf &V, const Eigen::MatrixXf &VN,\n\tconst Eigen::MatrixXf &VT, const Eigen::MatrixXi &F,\n\tEigen::MatrixXf &T, Eigen::MatrixXf &B)\n{\n\t//////////\n\t// TODO (Ex.4, Optional):\n\t// Compute the tangent frame formed by (T,B,N), such that T and B follows\n\t// the direction of U and V respectively.\n\t//////////\n\n\tT.resizeLike(V);\n\tB.resizeLike(V);\n\tT.setZero();\n\tB.setZero();\n}\n\nvoid generateInitialScale() {\n    Eigen::Matrix4f initialTranslation0 = Eigen::Matrix4f::Identity();\n    Eigen::Matrix4f initialTranslation1 = Eigen::Matrix4f::Identity();\n    Eigen::Matrix4f initialScale = Eigen::Matrix4f::Identity();\n\n    float currentMeshMaxValX;\n    float currentMeshMaxValY;\n    float currentMeshMaxValZ;\n    float currentMeshMinValX;\n    float currentMeshMinValY;\n    float currentMeshMinValZ;\n\n    for (int i = 0; i < fruit.V.cols(); i++) {\n\n        if (i == 0) {\n            currentMeshMaxValX = fruit.V(0, i);\n            currentMeshMaxValY = fruit.V(1, i);\n            currentMeshMaxValZ = fruit.V(2, i);\n            currentMeshMinValX = fruit.V(0, i);\n            currentMeshMinValY = fruit.V(1, i);\n            currentMeshMinValZ = fruit.V(2, i);\n\n\n        } else {\n\n            if (fruit.V(0, i) > currentMeshMaxValX) {\n\n                currentMeshMaxValX = fruit.V(0, i);\n            }\n\n            if (fruit.V(1, i) > currentMeshMaxValY) {\n                currentMeshMaxValY = fruit.V(1, i);\n            }\n            if (fruit.V(2, i) > currentMeshMaxValZ) {\n                currentMeshMaxValZ = fruit.V(2, i);\n            }\n\n            if (fruit.V(0, i) < currentMeshMinValX) {\n\n                currentMeshMinValX = fruit.V(0, i);\n            }\n            if (fruit.V(1, i) < currentMeshMinValY) {\n                currentMeshMinValY = fruit.V(1, i);\n            }\n            if (fruit.V(2, i) < currentMeshMinValZ) {\n                currentMeshMinValZ = fruit.V(2, i);\n            }\n\n\n        }\n    }\n\n    initialTranslation0(0, 3) = -currentMeshMinValX;\n    initialTranslation0(1, 3) = -currentMeshMinValY;\n    initialTranslation0(2, 3) = -currentMeshMinValZ;\n\n\n    initialScale(0, 0) = 1 / (currentMeshMaxValX - currentMeshMinValX);\n    initialScale(1, 1) = 1 / (currentMeshMaxValY - currentMeshMinValY);\n    initialScale(2, 2) = 1 / (currentMeshMaxValZ - currentMeshMinValZ);\n\n    for (int i = 0; i < 3; i++) {\n        if (isinf(initialScale(i, i))) {\n            initialScale(i,i) = 1;\n        }\n    }\n\n    initialTranslation1(0, 3) = -0.5;\n    initialTranslation1(1, 3) = -0.5;\n    initialTranslation1(2, 3) = -0.5;\n\n\n    fruit.initialTransformation = initialTranslation1 * initialScale * initialTranslation0;\n\tfruit.initialTransformationNormals = fruit.initialTransformation.transpose().inverse();\n\n}\n\nvoid applyInitialTransformation() {\n\tEigen::MatrixXf newV(fruit.V.rows(), fruit.V.cols()); // vertices positions [3 x n]\n\tEigen::MatrixXf newVN(fruit.VN.rows(), fruit.VN.cols()); // vertices positions [3 x n]VN\n\tEigen::Vector4f homogVect;\n\tEigen::Vector3f newCol;\n\tfor (int i = 0; i < fruit.V.cols(); i++) {\n\t\thomogVect = {fruit.V(0, i), fruit.V(1, i), fruit.V(2, i), 1.0};\n\t\thomogVect = fruit.initialTransformation*homogVect;\n\t\tnewCol = {homogVect(0), homogVect(1), homogVect(2)};\n\t\tnewV.col(i) = newCol;\n\t}\n\n\tfor (int i =0 ; i < fruit.VN.cols(); i++) {\n\t\thomogVect = {fruit.VN(0, i), fruit.VN(1, i), fruit.VN(2, i), 1.0};\n\t\thomogVect = fruit.initialTransformationNormals * homogVect;\n\t\tnewCol = {homogVect(0), homogVect(1), homogVect(2)};\n\t\tnewVN.col(i) = newCol;\n\t}\n\n\n\tfruit.V = newV;\n\tfruit.VN = newVN;\n\t// Set transformation matrix for normals m.initialTransformationNormal = ...\n\n\n}\n\nvoid toggleUVMapping() {\n\tif (!showingUVMapping) {\n\t\tEigen::MatrixXf newV(fruit.V.rows(), fruit.V.cols());\n\t\tEigen::MatrixXf newVN(fruit.VN.rows(), fruit.VN.cols());\n\n\t\tEigen::Vector2f currentUV;\n\t\tEigen::Vector3f newVCol;\n        Eigen::Vector3f newVNCol;\n\t\tfor (int i = 0; i < newV.cols(); i++) {\n\t\t\tcurrentUV = fruit.VT.col(i);\n\t\t\tnewVCol = {currentUV[0] - .5 , currentUV[1] - .5, 0};\n\t\t\tnewV.col(i) = newVCol;\n\t\t\tnewVNCol = {0.0f, 0.0f, 1.0f};\n            newVN.col(i) = newVNCol;\n        }\n\n        showingUVMapping = true;\n\n        fruit.V = newV;\n        fruit.VN = newVN;\n        fruit.V_vbo.update(newV);\n        fruit.norm_vbo.update(newVN);\n\t}\n\n\n}\n\n\nvoid load_model(const std::string &mesh_filename,\n\tconst std::string &color_filename, const std::string &bump_filename) {\n    // Load the model\n    Eigen::MatrixXf V, VT, VN;\n    Eigen::MatrixXi F, FT, FN;\n    load_obj(std::string(DATA_DIR) + mesh_filename, V, VT, VN, F, FT, FN);\n    assert(F.cols() == FT.cols() && FT.cols() == FN.cols());\n\n\n    Eigen::MatrixXf newV(3, 3 * F.cols());\n    Eigen::MatrixXi newF(3, F.cols());\n    Eigen::MatrixXf newVT(2, 3 * F.cols());\n    Eigen::MatrixXf newNormals(3, 3 * F.cols());\n\n    fruit.V = V;\n    generateInitialScale();\n\n    for (int i = 0; i < F.cols(); i++) {\n        for (int j = 0; j < 3; j++) {\n            newV.col((i*3) + j) = V.col(F(j, i));\n            newF(j, i) = (i * 3) + j;\n            newVT.col((i*3) + j) = VT.col(FT(j,i));\n            newNormals.col((i * 3) + j) = VN.col(FN(j,i));\n        }\n    }\n\n//    std::cout << newVT.cols() <<std::endl;\n//    std::cout << newV.cols() <<std::endl;\n//    std::cout << newF.cols() <<std::endl;\n    fruit.V = newV;\n    fruit.F = newF;\n    fruit.VT = newVT;\n    fruit.VN = newNormals;\n\n    // Compute tangent frame\n    // compute_tangent_frame(fruit.V, fruit.VN, fruit.VT, fruit.F, fruit.T, fruit.B);\n\n    // Update GPU data\n    glBindVertexArray(0);\n\n\n    // Load textures\n    load_image(std::string(DATA_DIR) + color_filename, fruit.pixels_color);\n    load_image(std::string(DATA_DIR) + bump_filename, fruit.normal_texture);\n\n    glActiveTexture(GL_TEXTURE0);\n    glBindTexture(GL_TEXTURE_2D, fruit.textures[0]);\n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA,\n                 fruit.pixels_color.rows(), fruit.pixels_color.cols(),\n                 0, GL_RGBA, GL_UNSIGNED_BYTE,\n                 reinterpret_cast<unsigned char *>(fruit.pixels_color.data()));\n\n\n    glActiveTexture(GL_TEXTURE1);\n    glBindTexture(GL_TEXTURE_2D, fruit.textures[1]);\n    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA,\n                 fruit.normal_texture.rows(), fruit.normal_texture.cols(),\n                 0, GL_RGBA, GL_UNSIGNED_BYTE,\n                 reinterpret_cast<unsigned char *>(fruit.normal_texture.data()));\n\n\n\n    applyInitialTransformation();\n    fruit.originalV = fruit.V;\n    fruit.originalVN = fruit.VN;\n\n    fruit.F_vbo.update(fruit.F);\n    fruit.V_vbo.update(fruit.V);\n    fruit.tex_vbo.update(fruit.VT);\n    fruit.norm_vbo.update(fruit.VN);\n\n\n}\n\nvoid key_callback(GLFWwindow* window, int key, int scancode, int action, int mods) {\n\tif (action == GLFW_PRESS) {\n\t\t// Update the position of the first vertex if the keys 1,2, or 3 are pressed\n\t\tswitch (key) {\n\t\t\tcase GLFW_KEY_1:\n\t\t\t\tuseBumpMapping = false;\n\t\t\t\tload_model("orange.obj", "orange.color.png", "orange.bump.png");\n\t\t\t\tcurrentModel = 1;\n                usingMultipleTextures = false;\n                showingUVMapping = false;\n\t\t\t\tbreak;\n\t\t\tcase GLFW_KEY_2:\n\t\t\t\tuseBumpMapping = false;\n\t\t\t\tload_model("banana.obj", "banana.color.png", "banana.bump.png");\n\t\t\t\tcurrentModel = 2;\n                usingMultipleTextures = false;\n                showingUVMapping = false;\n                break;\n\t\t\tcase GLFW_KEY_3:\n\t\t\t\tuseBumpMapping = false;\n\t\t\t\tcurrentModel = 3;\n\t\t\t\tload_model("wall.obj", "wall.color.jpg", "wall.bump.jpg");\n                usingMultipleTextures = false;\n                showingUVMapping = false;\n                break;\n\t\t\tcase GLFW_KEY_4:\n\t\t\t\tuseBumpMapping = false;\n\t\t\t\tcurrentModel = 3;\n                showingUVMapping = false;\n                usingMultipleTextures = true;\n\t\t\t\tload_model("wall.obj", "wall.color.jpg", "wall.normal.jpg");\n                break;\n\n\t\t\tcase GLFW_KEY_5:\n\t\t\t\tuseBumpMapping = false;\n\t\t\t\tcurrentModel =4;\n                usingMultipleTextures = false;\n\t\t\t\tload_model("sphere.obj", "wall.color.jpg", "wall.bump.jpg");\n                showingUVMapping = false;\n\t\t\t\tbreak;\n\t\t\tcase GLFW_KEY_U:\n\t\t\t\tuseBumpMapping = false;\n\t\t\t\tusingMultipleTextures = false;\n\t\t\t\tif (!showingUVMapping) {\n\t\t\t\t\ttoggleUVMapping();\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase GLFW_KEY_B:\n\t\t\t\tuseBumpMapping = true;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t}\n\t}\n}\n\n////////////////////////////////////////////////////////////////////////////////\n\nint main(void) {\n\t// Initialize the GLFW library\n\tif (!glfwInit()) {\n\t\treturn -1;\n\t}\n\n\t// Activate supersampling\n\tglfwWindowHint(GLFW_SAMPLES, 8);\n\n\t// Ensure that we get at least a 3.2 context\n\tglfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3);\n\tglfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 2);\n\n\t// On apple we have to load a core profile with forward compatibility\n#ifdef __APPLE__\n\tglfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE);\n\tglfwWindowHint(GLFW_OPENGL_FORWARD_COMPAT, GL_TRUE);\n#endif\n\n\t// Create a windowed mode window and its OpenGL context\n\tGLFWwindow * window = glfwCreateWindow(640, 640, "[Float] Hello World", NULL, NULL);\n\tif (!window) {\n\t\tglfwTerminate();\n\t\treturn -1;\n\t}\n\n\tstd::cout << "Offset" <<std::endl;\n\tstd::cout << GL_MIN_PROGRAM_TEXEL_OFFSET<<std::endl;\n\tstd::cout << GL_MAX_PROGRAM_TEXEL_OFFSET<<std::endl;\n\n\t// Make the window\'s context current\n\tglfwMakeContextCurrent(window);\n\n\t// Load OpenGL and its extensions\n\tif (!gladLoadGL()) {\n\t\tprintf("Failed to load OpenGL and its extensions");\n\t\treturn(-1);\n\t}\n\tprintf("OpenGL Version %d.%d loaded", GLVersion.major, GLVersion.minor);\n\n\tint major, minor, rev;\n\tmajor = glfwGetWindowAttrib(window, GLFW_CONTEXT_VERSION_MAJOR);\n\tminor = glfwGetWindowAttrib(window, GLFW_CONTEXT_VERSION_MINOR);\n\trev = glfwGetWindowAttrib(window, GLFW_CONTEXT_REVISION);\n\tprintf("OpenGL version recieved: %d.%d.%d\n", major, minor, rev);\n\tprintf("Supported OpenGL is %s\n", (const char*)glGetString(GL_VERSION));\n\tprintf("Supported GLSL is %s\n", (const char*)glGetString(GL_SHADING_LANGUAGE_VERSION));\n\n\t// Initialize the OpenGL Program\n\t// A program controls the OpenGL pipeline and it must contains\n\t// at least a vertex shader and a fragment shader to be valid\n\tProgram program;\n\tstd::string vertex_shader = load_text(SHADER_DIR "shader.vert");\n\tstd::string fragment_shader = load_text(SHADER_DIR "shader.frag");\n\n\t// Compile the two shaders and upload the binary to the GPU\n\t// Note that we have to explicitly specify that the output "slot" called outColor\n\t// is the one that we want in the fragment buffer (and thus on screen)\n\tprogram.init(vertex_shader, fragment_shader, "outColor");\n\n\t// Prepare a dummy fruit object\n\t// We need to initialize and fill the two VBO (vertex positions + indices),\n\t// and use a VAO to store their layout when we use our shader program later.\n\t{\n\t\t// Initialize the VBOs\n\t\tfruit.V_vbo.init(GL_FLOAT, GL_ARRAY_BUFFER);\n        fruit.tex_vbo.init(GL_FLOAT, GL_ARRAY_BUFFER);\n        fruit.norm_vbo.init(GL_FLOAT, GL_ARRAY_BUFFER);\n\n\t\tfruit.F_vbo.init(GL_UNSIGNED_INT, GL_ELEMENT_ARRAY_BUFFER);\n\n\t\t// Vertex positions\n\t\tfruit.V.resize(3, 3);\n\t\tfruit.V <<\n\t\t\t0, 0.5, -0.5,\n\t\t\t0.5, -0.5, -0.5,\n\t\t\t0, 0, 0;\n\t\tfruit.V_vbo.update(fruit.V);\n\n\t\t// Normals\n\t\tfruit.VN.resize(3, 3);\n\t\tfruit.VN <<\n\t\t\t0, 0, 0,\n\t\t\t0, 0, 0,\n\t\t\t1, 1, 1;\n\n        fruit.norm_vbo.update(fruit.VN);\n\n\t\t// Texture coordinates\n\t\tfruit.VT.resize(2, 3);\n\t\tfruit.VT <<\n\t\t\t0, 0, 1,\n\t\t\t0, 1, 0;\n        fruit.tex_vbo.update(fruit.VT);\n\n\t\t// Triangle indices\n\t\tfruit.F.resize(3, 1);\n\t\tfruit.F << 0, 1, 2;\n\t\tfruit.F_vbo.update(fruit.F);\n\n\t\t// Texture id\n\t\tglGenTextures(0, &fruit.textures[0]);\n        glGenTextures(1, &fruit.textures[1]);\n\n\t\tfloat pixels[] = {\n\t\t\t1.0f, 0.0f, 0.0f, 0.0f, 1.0f, 0.0f,\n\t\t\t0.0f, 0.0f, 1.0f, 0.0f, 0.0f, 0.0f\n\t\t};\n\n\t\t// Bind texture and upload data to GPU\n\t\tglBindTexture(GL_TEXTURE_2D, fruit.textures[0]);\n\t\tglTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 2, 2, 0, GL_RGB, GL_FLOAT, pixels);\n\t\t// Set interpolation parameters for the currently bound texture\n\t\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n\t\tglTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\n        glBindTexture(GL_TEXTURE_2D, fruit.textures[1]);\n        glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, 2, 2, 0, GL_RGB, GL_FLOAT, pixels);\n\n        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);\n        glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);\n\n\t\t// Create a new VAO for the fruit. and bind it\n\t\tfruit.vao.init();\n\t\tfruit.vao.bind();\n\n\t\t// Bind the element buffer, this information will be stored in the current VAO\n\t\tfruit.F_vbo.bind();\n\n\t\t// The vertex shader wants the position of the vertices as an input.\n\t\t// The following line connects the VBO we defined above with the position "slot"\n\t\t// in the vertex shader\n\t\tprogram.bindVertexAttribArray("vtxPosition", fruit.V_vbo);\n        program.bindVertexAttribArray("vtxTexCoord", fruit.tex_vbo);\n        program.bindVertexAttribArray("vtxNormal", fruit.norm_vbo);\n\n\t\t// Unbind the VAO when I am done\n\t\tfruit.vao.unbind();\n\n    }\n\n\n\t// For the first exercises, \'view\' and \'proj\' will be the identity matrices\n\t// However, the \'model\' matrix must change for each model in the scene\n\tEigen::Matrix4f modelMatrix = Eigen::Matrix4f::Identity();\n\tEigen::Matrix4f viewMatrix = Eigen::Matrix4f::Identity();\n\tEigen::Matrix4f projMatrix = Eigen::Matrix4f::Identity();\n\tEigen::Matrix4f normalMatrix = Eigen::Matrix4f::Identity();\n\tprojMatrix(2, 2) = -1; // Projection matrix in OpenGL inverts the Z coordinate\n\tprogram.bind();\n\tglUniformMatrix4fv(program.uniform("view"), 1, GL_FALSE, viewMatrix.data());\n\tglUniformMatrix4fv(program.uniform("proj"), 1, GL_FALSE, projMatrix.data());\n\n\t// Save the current time --- it will be used to dynamically change the triangle color\n\tauto t_start = std::chrono::high_resolution_clock::now();\n\n\t// Register the keyboard callback\n\tglfwSetKeyCallback(window, key_callback);\n\n\t// Loop until the user closes the window\n\twhile (!glfwWindowShouldClose(window)) {\n\t\t// Set the size of the viewport (canvas) to the size of the application window (framebuffer)\n\t\tint width, height;\n\t\tglfwGetFramebufferSize(window, &width, &height);\n\t\tglViewport(0, 0, width, height);\n\n\t\t// Clear the framebuffer\n\t\tglClearColor(0.5f, 0.5f, 0.5f, 1.0f);\n\t\tglClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);\n\n\t\t// Enable depth test\n\t\tglEnable(GL_DEPTH_TEST);\n        glDisable(GL_CULL_FACE);\n\n\t\t// Bind your program\n\t\tprogram.bind();\n        glUniform3f(program.uniform("meshColor"),0.0, 0.0, 0.0);\n        if (usingMultipleTextures) {\n            glUniform1f(program.uniform("shadingMode"), 2);\n        }\n        else if (useBumpMapping){\n\t\t\tglUniform1f(program.uniform("shadingMode"), 3);\n        }\n\t\telse {\n\t\t\tglUniform1f(program.uniform("shadingMode"), 0);\n\t\t}\n\n\n\t\t{\n\t\t\t// Bind the VAO for the fruit\n\t\t\tfruit.vao.bind();\n\n\t\t\t//////////\n\t\t\t// TODO: Bind the fruit texture to the texture unit 0\n\t\t\t//////////\n\n\n\t\t\t//////////\n\t\t\t// TODO: Set the sampler \'colorSampler\' to use the texture unit 0\n\t\t\t//////////\n\n            glActiveTexture(GL_TEXTURE0);\n            glBindTexture(GL_TEXTURE_2D, fruit.textures[0]);\n            glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA,\n                         fruit.pixels_color.rows(), fruit.pixels_color.cols(),\n                         0, GL_RGBA, GL_UNSIGNED_BYTE,\n                         reinterpret_cast<unsigned char *>(fruit.pixels_color.data()));\n\n            glUniform1i(glGetUniformLocation(program.program_shader, "texColor"), 0);\n\n            glActiveTexture(GL_TEXTURE1);\n            glBindTexture(GL_TEXTURE_2D, fruit.textures[1]);\n            glTexImage2D(GL_TEXTURE_2D, 0, GL_RGBA,\n                         fruit.normal_texture.rows(), fruit.normal_texture.cols(),\n                         0, GL_RGBA, GL_UNSIGNED_BYTE,\n                         reinterpret_cast<unsigned char *>(fruit.normal_texture.data()));\n\n            glUniform1i(glGetUniformLocation(program.program_shader, "texNormal"), 1);\n\n\t\t\t// Model matrix for the fruit\n\t\t\tglUniformMatrix4fv(program.uniform("model"), 1, GL_FALSE, modelMatrix.data());\n\n\t\t\t// Transform normals from the obj space to the camera space\n\t\t\tglUniformMatrix4fv(program.uniform("normalMatrix"), 1, GL_FALSE, normalMatrix.data());\n\n\t\t\t// Set the uniform value depending on the time difference\n            auto t_now = std::chrono::high_resolution_clock::now();\n            float time = std::chrono::duration_cast<std::chrono::duration<float>>(t_now - t_start).count();\n\n\t\t\tif (currentModel == 3) {\n\t\t\t\tglUniform3f(program.uniform("lightPosition"), .5f*cos(time), .5f*sin(time), 1.0);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tglUniform3f(program.uniform("lightPosition"), .70f*cos(time), .70f*sin(time), 1.0);\n\t\t\t}\n\n\n            glPolygonMode( GL_FRONT_AND_BACK, GL_FILL );\n\n\t\t\t// Draw the triangles\n\t\t\tglDrawElements(GL_TRIANGLES, 3 * fruit.F.cols(), fruit.F_vbo.scalar_type, 0);\n            if (showingUVMapping) {\n                glUniform1f(program.uniform("shadingMode"), 1);\n                for (int i = 0; i < fruit.V.cols(); i++) {\n                    fruit.V(2, i) = (.1);\n                }\n                fruit.V_vbo.update(fruit.V);\n                glPolygonMode( GL_FRONT_AND_BACK, GL_LINE );\n\n                glDrawElements(GL_TRIANGLES, 3 * fruit.F.cols(), fruit.F_vbo.scalar_type, 0);\n\n                glUniform1f(program.uniform("shadingMode"), 0);\n                for (int i = 0; i < fruit.V.cols(); i++) {\n                    fruit.V(2, i) = (0);\n                }\n                fruit.V_vbo.update(fruit.V);\n\n            }\n\t\t}\n\n\t\t// Swap front and back buffers\n\t\tglfwSwapBuffers(window);\n\n\t\t// Poll for and process events\n\t\tglfwPollEvents();\n\t}\n\n\t// Deallocate opengl memory\n\tprogram.free();\n\tfruit.vao.free();\n\tfruit.V_vbo.free();\n\tfruit.F_vbo.free();\n    fruit.norm_vbo.free();\n    fruit.tex_vbo.free();\n\tglDeleteTextures(1, &fruit.textures[0]);\n    glDeleteTextures(1, &fruit.textures[1]);\n\n\t// Deallocate glfw internals\n\tglfwTerminate();\n\treturn 0;\n}'},{name:"Shader",codeSnippet:"#version 150 core\nuniform sampler2D texColor;\nuniform sampler2D texNormal;\n\nuniform vec3 lightPosition;\nuniform float shadingMode;\nuniform vec3 meshColor;\n\nin vec3 eyePosition;\nin vec3 eyeNormal;\nin vec2 texCoord;\nin vec2 normalCoord;\n\n\n\nout vec4 outColor;\n\nvec3 compute_normal() {\n\n\treturn normalize(eyeNormal);\n}\n\n\nvec3 mapNormalValue(vec3 norm) {\n    return (2 * (norm)) - 1;\n\n}\n\nvec3 compute_textured_normal() {\n\tvec3 normalFromTexture = normalize(mapNormalValue(vec3(texture(texNormal, texCoord))));\n\treturn normalFromTexture;\n}\n\nvec3 compute_bump_normal() {\n    float heightx1 = textureOffset(texNormal, texCoord, ivec2(-1, 0))[0];\n    float heightx2 = textureOffset(texNormal, texCoord, ivec2(1, 0))[0];\n    float heighty1 = textureOffset(texNormal, texCoord, ivec2(0, -1))[0];\n    float heighty2 = textureOffset(texNormal, texCoord, ivec2(0, 1))[0];\n    vec3 t1 = vec3(1, 0, heightx2 - heightx1);\n    vec3 t2 = vec3(0, 1, heighty2 - heighty1);\n \treturn normalize(cross(t1, t2));\n}\n\nvoid main() {\n\t// Shading\n    vec3 Ka = vec3(0.200000, 0.200000, 0.200000);\n    vec3 Kd = vec3(0.749020, 0.749020, 0.749020);\n    vec3 Ks = vec3(0.500000, 0.500000, 0.500000);\n    float shininess = 100.0;\n\n    vec3 ambientColor = vec3(1, 1, 1);\n    vec3 diffuseColor = vec3(1, 1, 1);\n    vec3 specularColor = vec3(1, 1, 1);\n\n\tif (shadingMode != 1) {\n\n    \t// Compute the normal to the fragment\n        vec3 N;\n    \tif (shadingMode == 0) {\n    \t    N = compute_normal();\n    \t}\n        else if (shadingMode == 3){\n            N = compute_bump_normal();\n        }\n    \telse {\n    \t    N = compute_textured_normal();\n    \t}\n\n\n    \tvec3 v = normalize((-1 * eyePosition + lightPosition));\n\n        float lambertian = min(1, max(0, dot(N, lightPosition - eyePosition)));\n    \tfloat specular = pow(max(0, dot(N, v)), 50);\n    \tvec3 shadedColor = vec3(Ka * ambientColor + Kd * lambertian * diffuseColor + Ks * specular * specularColor);\n\n    \t// Draw the light bulb\n    \tif (distance(eyePosition.xy, lightPosition.xy) < .1) {\n    \t\toutColor = vec4(1, 1, 0, 0);\n    \t\treturn;\n    \t}\n    \telse {\n\n\n        \toutColor = texture(texColor, texCoord) * vec4(shadedColor, 1.0);\n        \treturn;\n    \t}\n\n\t}\n\n\n\telse if (shadingMode == 1) {\n\t    outColor = vec4(meshColor, 1.0);\n\t}\n}"}]}),Object(p.jsx)(M,{projectName:"Basic Geometry",projectDescription:e,images:[Object(p.jsx)(P,{imageSrc:"/jacob-helfgot/images/convex_hull_result.png",caption:"The convex-hull."}),Object(p.jsx)(P,{imageSrc:"/jacob-helfgot/images/point_in_poly_results.png",caption:"The points found within the polygon colored red."})],codeSnippets:[{name:"Convex Hull",codeSnippet:'////////////////////////////////////////////////////////////////////////////////\n#include <algorithm>\n#include <numeric>\n#include <complex>\n#include <fstream>\n#include <iostream>\n#include <numeric>\n#include <vector>\n\n////////////////////////////////////////////////////////////////////////////////\n\ntypedef std::complex<double> Point;\n\ntypedef std::vector<Point> Polygon;\n\ndouble pi = 3.1415926535897;\nstd::vector <Point> holder;\ndouble inline det(const Point &u, const Point &v) {\n\n\treturn 0;\n}\n\nbool isSamePoint(Point a, Point b) {\n    if (a.real() == b.real() && a.imag() == b.imag()) {\n        return true;\n    }\n    return false;\n}\n\nfloat dotProd(Point &a, const Point &b) {\n    return (a.imag() * b.imag()) + (a.real() * b.real());\n}\n\nfloat ccw(Point &p1, Point &p2, Point &p3) {\n    return ((p2.real() - p1.real()) * (p3.imag() - p1.imag())) - ((p2.imag() - p1.imag()) * (p3.real() - p1.real()));\n}\n\nstruct Compare {\n\tPoint p0; // Leftmost point of the poly\n\tbool operator ()(const Point &p1, const Point &p2) {\n//\n//\n//        if (p1.real() - p0.real() == 0) {\n//            angle1 =\n//        }\n//        else if (p2.real - p0.real() == 0) {\n//            return false;\n//        }\n\n        float angle1 = atan((p1.imag() - p0.imag())/(p1.real()-p0.real()));\n        float angle2 = atan((p2.imag() - p0.imag())/(p2.real()-p0.real()));\n        if (angle1 < 0) {\n            angle1 = (pi/2) + ((pi/2) + angle1);\n        }\n        if (angle2 < 0) {\n            angle2 = (pi/2) + ((pi/2) + angle2);\n        }\n//        float dot1 = dotProd(p0, p1);\n//        float dot2 = dotProd(p0, p2);\n        return (angle1 < angle2);\n\n\t}\n};\n\nbool inline salientAngle(Point &a, Point &b, Point &c) {\n\n\n\treturn false;\n}\n\n\nPoint findLeftBottomPoint(std::vector<Point> v) {\n\tstd::vector <Point> solutions;\n    std::vector <int> mindexes;\n\tif (v.size() > 0) {\n\t\tsolutions.push_back(v[0]);\n        mindexes.push_back(0);\n        for (int i = 1; i < v.size(); i++) {\n            if(v[i].imag() < solutions[0].imag()) {\n\n                solutions.clear();\n                mindexes.clear();\n                solutions.push_back(v[i]);\n                mindexes.push_back(i);\n\n            }\n            else if (v[i].imag() == solutions[0].imag()) {\n                solutions.push_back(v[i]);\n                mindexes.push_back(i);\n            }\n\n\n        }\n    }\n\n    if (solutions.size() > 1) {\n\n        Point absoluteMinimum = solutions[0];\n        int minDexFinal = 0;\n\n        for (int j = 1; j < solutions.size(); j++) {\n            if (solutions[j].real() < absoluteMinimum.real()) {\n                absoluteMinimum = solutions[j];\n                minDexFinal = j;\n            }\n        }\n        v.erase(v.begin() + minDexFinal);\n        return absoluteMinimum;\n\n\n    }\n    else {\n        v.erase(v.begin() + mindexes[0]);\n\n        holder = v;\n        return solutions[0];\n    }\n\n}\n\n////////////////////////////////////////////////////////////////////////////////\n\nPolygon convex_hull(std::vector<Point> &points) {\n    if (points.size() < 3) {\n        exit(1);\n    }\n\tCompare order;\n    Polygon hull;\n\torder.p0 = findLeftBottomPoint(points);\n    points = holder;\n\tstd::sort(points.begin(), points.end(), order);\n\n    hull.push_back(order.p0);\n    hull.push_back(points[0]);\n    int m = 2;\n\n    for (int i = 0; i < points.size(); i++) {\n\n        while (ccw(hull[m-2], hull[m-1], points[i]) < 0) {\n\n            m--;\n            hull.erase(hull.begin() + m);\n\n        }\n\n\n        hull.push_back(points[i]);\n        m++;\n\n\n\n    }\n\n    // salientAngle(a, b, c) here\n\treturn hull;\n}\n\n////////////////////////////////////////////////////////////////////////////////\n\nstd::vector<Point> load_xyz(const std::string &filename) {\n\tstd::vector<Point> points;\n\tstd::ifstream in(filename);\n\tstd::string newLine;\n\tint numLines;\n\tif (!in) {\n\t\tstd::cerr<<"Unable to open file"<<std::endl;\n\t\texit(1);\n\t}\n\n\tin >> numLines;\n\tfloat xVal, yVal, zVal;\n\tfor (int i = 0; i < numLines; i++) {\n\t\tin >> xVal;\n\t\tin >> yVal;\n\t\tin >> zVal;\n\t\tpoints.push_back(Point(xVal, yVal));\n\t}\n\n\treturn points;\n}\n\nPolygon load_obj(const std::string &filename) {\n    Polygon newPoly;\n    std::ifstream in(filename);\n    std::string newLine;\n    int numLines;\n    if (!in) {\n        std::cerr<<"Error opening polygon file" <<std::endl;\n        exit(1);\n    }\n    in >> numLines;\n    float xVal, yVal, zVal;\n    for (int i = 0; i < numLines; i++) {\n        in >> xVal;\n        in >> yVal;\n        in >> zVal;\n        newPoly.push_back(Point(xVal, yVal));\n    }\n    return newPoly;\n}\n\nvoid save_obj(const std::string &filename, Polygon &poly) {\n\tstd::ofstream out(filename);\n\tif (!out.is_open()) {\n\t\tthrow std::runtime_error("failed to open file " + filename);\n\t}\n\tout << std::fixed;\n\tfor (const auto &v : poly) {\n\t\tout << "v " << v.real() << \' \' << v.imag() << " 0\n";\n\t}\n\tfor (size_t i = 0; i < poly.size(); ++i) {\n\t\tout << "l " << i+1 << \' \' << 1+(i+1)%poly.size() << "\n";\n\t}\n\tout << std::endl;\n}\n\n\n////////////////////////////////////////////////////////////////////////////////\n\nint main(int argc, char * argv[]) {\n\tif (argc <= 2) {\n\t\tstd::cerr << "Usage: " << argv[0] << " points.xyz output.obj" << std::endl;\n\t}\n\tstd::vector<Point> points = load_xyz(argv[1]);\n\n\n    Point leftMost = findLeftBottomPoint(points);\n\n    Polygon hull = convex_hull(points);\n\n    std::ofstream convexHullFile("../data/output.obj");\n\n\n    for (int i = 0; i < hull.size(); i++) {\n        convexHullFile << "v " << hull[i].real() << " " << hull[i].imag() << " 0\n";\n    }\n    convexHullFile << "f ";\n    for (int i = 1; i <= hull.size(); i++) {\n        convexHullFile << i << " ";\n    }\n    std::ofstream objFile("../data/object.xy");\n    for (int i = 0; i < points.size(); i++) {\n        objFile << points[i].real() << " " << points[i].imag() << std::endl;\n    }\n\n    std::ofstream hullFile("../data/hull.xy");\n    for (int i = 0; i <= hull.size(); i++) {\n        hullFile << hull[i].real() << " " << hull[i].imag() << std::endl;\n    }\n\n\n\n\n\n\n\n\t//save_obj(argv[2], hull);\n\n\treturn 0;\n}'},{name:"Point Inside Polygon",codeSnippet:'////////////////////////////////////////////////////////////////////////////////\n#include <algorithm>\n#include <complex>\n#include <fstream>\n#include <iostream>\n#include <numeric>\n#include <math.h>\n#include <vector>\n////////////////////////////////////////////////////////////////////////////////\n\ntypedef std::complex<double> Point;\ntypedef std::vector<Point> Polygon;\nstd::vector <int> edges;\nstd::vector <Point> holder;\nstd::vector <Point> bounding_box;\n\ndouble pi = 3.1415926535897;\nstruct Compare {\n\tPoint p0; // Leftmost point of the poly\n\tbool operator ()(const Point &p1, const Point &p2) {\n//\n//\n//        if (p1.real() - p0.real() == 0) {\n//            angle1 =\n//        }\n//        else if (p2.real - p0.real() == 0) {\n//            return false;\n//        }\n\n\t\tfloat angle1 = atan((p1.imag() - p0.imag())/(p1.real()-p0.real()));\n\t\tfloat angle2 = atan((p2.imag() - p0.imag())/(p2.real()-p0.real()));\n\t\tif (angle1 < 0) {\n\t\t\tangle1 = (pi/2) + ((pi/2) + angle1);\n\t\t}\n\t\tif (angle2 < 0) {\n\t\t\tangle2 = (pi/2) + ((pi/2) + angle2);\n\t\t}\n//        float dot1 = dotProd(p0, p1);\n//        float dot2 = dotProd(p0, p2);\n\t\treturn (angle1 < angle2);\n\n\t}\n};\n\nfloat ccw(Point &p1, Point &p2, Point &p3) {\n\treturn ((p2.real() - p1.real()) * (p3.imag() - p1.imag())) - ((p2.imag() - p1.imag()) * (p3.real() - p1.real()));\n}\n\n\nPoint findLeftBottomPoint(std::vector<Point> v) {\n\tstd::vector <Point> solutions;\n\tstd::vector <int> mindexes;\n\tif (v.size() > 0) {\n\t\tsolutions.push_back(v[0]);\n\t\tmindexes.push_back(0);\n\t\tfor (int i = 1; i < v.size(); i++) {\n\t\t\tif(v[i].imag() < solutions[0].imag()) {\n\n\t\t\t\tsolutions.clear();\n\t\t\t\tmindexes.clear();\n\t\t\t\tsolutions.push_back(v[i]);\n\t\t\t\tmindexes.push_back(i);\n\n\t\t\t}\n\t\t\telse if (v[i].imag() == solutions[0].imag()) {\n\t\t\t\tsolutions.push_back(v[i]);\n\t\t\t\tmindexes.push_back(i);\n\t\t\t}\n\n\n\t\t}\n\t}\n\n\tif (solutions.size() > 1) {\n\n\t\tPoint absoluteMinimum = solutions[0];\n\t\tint minDexFinal = 0;\n\n\t\tfor (int j = 1; j < solutions.size(); j++) {\n\t\t\tif (solutions[j].real() < absoluteMinimum.real()) {\n\t\t\t\tabsoluteMinimum = solutions[j];\n\t\t\t\tminDexFinal = j;\n\t\t\t}\n\t\t}\n\t\tv.erase(v.begin() + minDexFinal);\n\t\treturn absoluteMinimum;\n\n\n\t}\n\telse {\n\t\tv.erase(v.begin() + mindexes[0]);\n\n\t\tholder = v;\n\t\treturn solutions[0];\n\t}\n\n}\n\n\ndouble inline det(const Point &u, const Point &v) {\n\t// TODO\n\treturn 0;\n}\n\n// Return true iff [a,b] intersects [c,d], and store the intersection in ans\n\n// used video https://www.youtube.com/watch?v=R08OY6yDNy0 as reference for this algorithm.\nbool intersect_segment(const Point &a, const Point &b, const Point &c, const Point &d, Point &ans) {\n\t// TODO\n\treturn true;\n}\n\nPolygon convex_hull(std::vector<Point> &points) {\n\tif (points.size() < 3) {\n\t\texit(1);\n\t}\n\tCompare order;\n\tPolygon hull;\n\torder.p0 = findLeftBottomPoint(points);\n\tpoints = holder;\n\tstd::sort(points.begin(), points.end(), order);\n\n\thull.push_back(order.p0);\n\thull.push_back(points[0]);\n\tint m = 2;\n\n\tfor (int i = 0; i < points.size(); i++) {\n\n\t\tif (points[i].real() > 310 && points[i].real() < 312) {\n\t\t}\n\n\t\twhile (ccw(hull[m-2], hull[m-1], points[i]) < 0) {\n\n\t\t\tm--;\n\t\t\thull.erase(hull.begin() + m);\n\n\t\t}\n\n\n\t\thull.push_back(points[i]);\n\t\tm++;\n\n\n\n\t}\n\n\t// salientAngle(a, b, c) here\n\treturn hull;\n}\n////////////////////////////////////////////////////////////////////////////////\n\nbool is_inside(Polygon &poly, const Point &query) {\n\n\t// 1. Compute bounding box and set coordinate of a point outside the polygon\n\n\t// TODO\n\n\t// 2. Cast a ray from the query point to the \'outside\' point, count number of intersections\n\t// TODO\n\treturn true;\n}\n\nfloat getOrientation(const Point &segPoint1, const Point &segPoint2, const Point &comparePoint) {\n\treturn ((segPoint2.imag() - segPoint1.imag()) * (comparePoint.real() - segPoint2.real()))\n\t\t\t- ((segPoint2.real() - segPoint1.real()) * (comparePoint.imag() - segPoint2.imag()));\n}\n\nbool onSegment(const Point &segPoint1, const Point &segPoint2, const Point &comparePoint) {\n\tbool pred1 = (std::min(segPoint1.real(), segPoint2.real()) <= comparePoint.real()\n\t\t\t\t  && std::max(segPoint1.real(), segPoint2.real()) >= comparePoint.real());\n\tbool pred2 = (std::min(segPoint1.imag(), segPoint2.imag()) <= comparePoint.imag()\n\t\t\t\t  && std::max(segPoint1.imag(), segPoint2.imag()) >= comparePoint.imag());\n\tif (pred1 && pred2) {\n\t\treturn true;\n\t}\n\n\telse {\n\t\treturn false;\n\t}\n\n\n}\nbool doIntersect(const Point &a, const Point &b, const Point &c, const Point &d) {\n\n\tfloat dir1 = (getOrientation(c, d, a));\n\tfloat dir2 = (getOrientation(c, d, b));\n\tfloat dir3 = (getOrientation(a, b, c));\n\tfloat dir4 = (getOrientation(a, b, d));\n\n\n\n\tif \t(((dir1 > 0 && dir2 < 0) || (dir1 < 0 && dir2 > 0)) && ((dir3 > 0 && dir4 < 0) || (dir3 < 0 && dir4 > 0))) {\n\t\treturn true;\n\t}\n\n\telse if (dir1 == 0 && onSegment(c, d, a)) {\n\t\treturn true;\n\t}\n\n\telse if (dir2 == 0 && onSegment(c, d, b)) {\n\t\treturn true;\n\t}\n\n\telse if (dir3 == 0 && onSegment(a, b, c)) {\n\t\treturn true;\n\t}\n\n\telse if (dir4 == 0 && onSegment(a, b, d)) {\n\t\treturn true;\n\t}\n\n\telse {\n\t\treturn false;\n\t}\n\n}\n\n////////////////////////////////////////////////////////////////////////////////\n\nstd::vector<Point> load_xyz(const std::string &filename) {\n\tstd::vector<Point> points;\n\tstd::ifstream in("../data/" + filename);\n\tif (!in) {\n\t\tstd::cerr<<"Error opening polygon file" <<std::endl;\n\t\texit(-1);\n\t}\n\telse {\n\t\tint numPoints;\n\t\tin >> numPoints;\n\n\t\tfor (int i = 0; i < numPoints; i++) {\n\t\t\tfloat x, y, z;\n\t\t\tstd::string letter;\n\t\t\tin >> x;\n\t\t\tin >> y;\n\t\t\tin >> z;\n\n\t\t\tpoints.push_back(Point(x, y));\n\t\t}\n\t\treturn points;\n\t}\n\n}\n\n\n\nPolygon load_obj(const std::string &filename) {\n\n\tstd::ifstream in("../data/" + filename);\n\n    if (!in) {\n        std::cerr<<"Error opening polygon file" <<std::endl;\n        exit(-1);\n\t}\n    else {\n\t\tPolygon newPoly;\n\t\tstd::string lineIndicator;\n\t\tin >> lineIndicator;\n\t\tfloat xCoord;\n\t\tfloat yCoord;\n\t\tfloat zCoord;\n\t\twhile (lineIndicator != "f" && !in.eof()) {\n\t\t\tin >> xCoord;\n\t\t\tin >> yCoord;\n\t\t\tin >> zCoord;\n\t\t\tnewPoly.push_back(Point(xCoord, yCoord));\n\t\t\tin >> lineIndicator;\n\t\t}\n\t\tint newEdge;\n\t\twhile(!in.eof()) {\n\t\t\tin >> newEdge;\n\t\t\tedges.push_back(newEdge);\n\t\t}\n\t\treturn newPoly;\n\t}\n\n\n}\n\nvoid save_xyz(const std::string &filename, const std::vector<Point> &points) {\n\tstd::ofstream out("../data/" + filename);\n\n\tif (!out) {\n\t\tstd::cerr<<"Error opening polygon file" <<std::endl;\n\t\texit(-1);\n\t}\n\telse {\n\t\tout << points.size() << std::endl;\n\t\tfor (int i = 0; i < points.size(); i++) {\n\n\t\t\tout << points[i].real() << " " << points[i].imag() << " 0.0" << std::endl;\n\n\t\t}\n\n\t\tout.close();\n\t}\n}\n\n\nPoint pointsInPolygon(std::vector <Point> &pointsInsidePoly, std::vector <Point> &pointsOutsidePoly,\n\t\t\t\t\t const Point &distantPoint, const std::vector <Point> pointsToCheck, const Polygon hull) {\n\n\tint totalInside = 0;\n\tint totalOutside = 0;\n\tfor (int i = 0; i < pointsToCheck.size(); i++) {\n\t\tint intersections = 0;\n\t\tfor (int j = 1; j < hull.size(); j++) {\n\n\t\t\tif (doIntersect(hull[j - 1], hull[j], pointsToCheck[i], distantPoint)) {\n\t\t\t\tintersections++;\n\t\t\t}\n\n\t\t}\n\t\tPoint newPoint = Point(pointsToCheck[i].real(), pointsToCheck[i].imag());\n\n\t\tif (intersections % 2 == 1) {\n\t\t\ttotalInside++;\n\t\t\tpointsInsidePoly.push_back(newPoint);\n\t\t}\n\t\telse {\n\t\t\ttotalOutside++;\n\t\t\tpointsOutsidePoly.push_back(newPoint);\n\t\t}\n\n\t}\n\n\treturn Point(totalInside, totalOutside);\n\n}\n\n\n\n////////////////////////////////////////////////////////////////////////////////\n\nint main(int argc, char * argv[]) {\n\tif (argc <= 3) {\n\t\tstd::cerr << "Usage: " << argv[0] << " points.xyz poly.obj result.xyz" << std::endl;\n\t}\n\tstd::vector<Point> points = load_xyz(argv[1]);\n\tPolygon poly = load_obj(argv[2]);\n\tstd::ofstream objectFile("../data/object.xy");\n\tfor (int i = 0; i < poly.size(); i++) {\n\n\t\tobjectFile << poly[i].real() << " " << poly[i].imag()<< std::endl;\n\t}\n\n\tobjectFile.close();\n\tstd::ofstream convexHullFile("../data/hull.xy");\n\n\tbounding_box = convex_hull(poly);\n\n\tfloat maxX = 0.0;\n\tfloat maxY = 0.0;\n\tfor (int i = 0; i < bounding_box.size(); i++) {\n\n\t\tconvexHullFile << bounding_box[i].real() << " " << bounding_box[i].imag()<< std::endl;\n\t\tif (bounding_box[i].real() > maxX) {\n\t\t\tmaxX = bounding_box[i].real();\n\t\t}\n\t\tif (bounding_box[i].imag() > maxY) {\n\t\t\tmaxY = bounding_box[i].imag();\n\t\t}\n\n\t}\n\n\n\tpoly = load_obj(argv[2]);\n\tPoint distantPoint = Point (maxX, maxY);\n\n\n\tconvexHullFile.close();\n\n\tstd::vector <Point> pointsInside;\n\tstd::vector <Point> pointsOutside;\n\n\n\tstd::vector <Point> polyCopy;\n\n\tfor (int i = 0; i < poly.size(); i++) {\n\t\tpolyCopy.push_back(Point(poly[i].real(), poly[i].imag()));\n\t}\n\tpolyCopy.push_back(poly[0]);\n\tPoint totals = pointsInPolygon(pointsInside, pointsOutside, distantPoint, points, polyCopy);\n\n\n\n\tsave_xyz( "insidePoints.xyz", pointsInside);\n\tsave_xyz( "outsidePoints.xyz", pointsOutside);\n\treturn 0;\n}'}]})]})},I=function(){return Object(p.jsxs)("div",{children:[Object(p.jsx)("a",{href:"https://www.linkedin.com/in/jacob-helfgot-b2b018127/",children:"LinkedIn"})," ","-- ",Object(p.jsx)("a",{href:"https://github.com/jhelfgot1",children:"GitHub"})]})};var E=function(){return Object(p.jsx)("div",{classname:"App",children:Object(p.jsxs)(s.a,{basename:"/jacob-helfgot",children:[Object(p.jsxs)(c.a,{fixed:"top",bg:"dark",variant:"dark",expand:"md",children:[Object(p.jsx)(c.a.Brand,{as:s.c,to:"/",children:"Jacob Helfgot"}),Object(p.jsx)(c.a.Toggle,{"aria-controls":"basic-navbar-nav"}),Object(p.jsxs)(c.a.Collapse,{id:"basic-navbar-nav",children:[Object(p.jsx)(d.a.Link,{exact:!0,as:s.c,to:"/",className:"link",activeClassName:"font-weight-bold",children:"Home"}),Object(p.jsx)(d.a.Link,{exact:!0,as:s.c,to:"/about",className:"link",activeClassName:"font-weight-bold",children:"About Me"}),Object(p.jsx)(d.a.Link,{as:s.c,to:"/contact",className:"link",activeClassName:"font-weight-bold",children:"Contact Me"}),Object(p.jsx)(u.a,{className:"link",title:"Academic Projects",id:"past-projects-dropdown",children:Object(p.jsx)(u.a.Item,{as:s.c,to:"/cg",children:"Computer Graphics"})})]})]}),Object(p.jsx)(l.c,{children:Object(p.jsxs)("div",{className:"pageContent",children:[Object(p.jsx)(l.a,{path:"/about",children:Object(p.jsx)(x,{})}),Object(p.jsx)(l.a,{path:"/contact",children:Object(p.jsx)(_,{})}),Object(p.jsx)(l.a,{path:"/cg",children:Object(p.jsx)(L,{})}),Object(p.jsx)(l.a,{exact:!0,path:"/",children:Object(p.jsx)(f,{})})]})}),Object(p.jsx)("div",{children:Object(p.jsx)(c.a,{bg:"light",fixed:"bottom",expand:"sm",children:Object(p.jsx)("div",{style:{margin:"auto"},children:Object(p.jsx)(I,{})})})})]})})};e(363);a.a.render(Object(p.jsx)(o.a.StrictMode,{children:Object(p.jsx)(E,{})}),document.getElementById("root"))}},[[364,1,2]]]);
//# sourceMappingURL=main.2dba3cc3.chunk.js.map